{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laucio/colab/blob/main/Te_damos_la_bienvenida_a_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "# 1 Introducción\n",
        "\n",
        "Una gran Rama de HPC es el procesamiento de lenguaje natural, que es una rama de la inteligencia artificial que ayuda a las computadoras a entender, interpretar y manipular el lenguaje humano.\n",
        "\n",
        "En el siguiente ejercicio vamos a partir de una cadena de texto, a la que vamos a aplicar una cadena de funciones para normalizarlo.\n",
        "\n",
        "El procesamiento de lenguaje natural nos puede servir para entender el sentimiento del texto, poder realizar acciones computacionales en base a ello o darle una connotación tanto positiva o negativa a la oración analizada, entre otras aplicaciones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfvgFR2jU6Dy"
      },
      "source": [
        "# Armado Ambiente\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WmA13U9VCpi",
        "outputId": "73c2bb8d-c3a3-44da-a1c1-8b07adff3a0b"
      },
      "source": [
        "!pip install pycuda\n",
        "!pip install lorem\n",
        "!pip install contractions\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2021.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2021.2.9)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.1.6)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: lorem in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.0.58-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 42.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85452 sha256=7a2f56dd5d7c3f8e3b5c5eacc0dea5a4b7cbcd88403d49a3e7f9ccb26962d173\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.58 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya63N2YiVTDK",
        "outputId": "31d32035-86a2-4692-fc40-911748542f6c"
      },
      "source": [
        "import lorem\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import re, string, unicodedata\n",
        "import nltk\n",
        "import contractions\n",
        "import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "texto = \"\"\"Nosotros y nuestros socios almacenamos o accedemos a información en un dispositivo, tales como cookies, y procesamos datos personales, tales como identificadores únicos e información estándar enviada por un dispositivo, para anuncios y contenido personalizados, medición de anuncios y del contenido e información sobre el público, así como para desarrollar y mejorar productos.\n",
        "Con su permiso, nosotros y nuestros socios podemos utilizar datos de localización geográfica precisa e identificación mediante las características de dispositivos. Puede hacer clic para otorgarnos su consentimiento a nosotros y a nuestros socios para que llevemos a cabo el procesamiento previamente descrito. De forma alternativa, puede acceder a información más detallada y cambiar sus preferencias antes de otorgar o negar su consentimiento.\n",
        "Tenga en cuenta que algún procesamiento de sus datos personales puede no requerir de su consentimiento, pero usted tiene el derecho de rechazar tal procesamiento. Sus preferencias se aplicarán solo a este sitio web. Puede cambiar sus preferencias en cualquier momento entrando de nuevo en este sitio web o visitando nuestra política de privacidad.\n",
        "En el Banco Central señalaron que hoy la tasa de interés para estas operaciones ronda -promedio- el 43 % anual Para el caso de pasajes y paquetes de turismo interno, los mismos se podrán comercializar a través del programa Ahora 12.\n",
        "\n",
        "Textualmente, la comunicación A 7407 difundida este jueves dice: “A partir del 26.11.21 las entidades financieras y no financieras emisoras de tarjetas de crédito no deberán financiar en cuotas las compras efectuadas mediante tarjetas de crédito de sus clientes –personas humanas y jurídicas– de pasajes al exterior y demás servicios turísticos en el exterior (tales como alojamiento, alquiler de auto, etc.), ya sea realizadas en forma directa con el prestador del servicio o indirecta, a través de agencia de viajes y/o turismo, plataformas web u otros intermediarios.”\n",
        "\n",
        "La nueva restricción que anunció el Banco Central refuerza la política de cuidar a como de lugar las cada vez más escasas reservas netas que administra el organismo que preside Miguel Pesce. El temor de las autoridades es que con la apertura de fronteras, las menores restricciones para ingresar a otros países y la llegada de la temporada de vacaciones la demanda de dólares por turismo se incrementará sensiblemente, aumentando la presión sobre las reservas.\n",
        "\n",
        "Según el último informe del mercado cambiario elaborado por el Banco Central, “las denominadas “personas humanas” compraron de forma neta US$ 326 millones, básicamente para gastos efectuados con tarjetas por consumos con proveedores no residentes (con un neto de US$ 149 millones, mostrando un incremento de 14% con respecto al mes anterior) y para atesoramiento (con un neto de US$ 134 millones en billetes, con un incremento de 8% respecto al mes previo y un descenso de 79% interanual). Asimismo, se realizaron transferencias de fondos hacia cuentas propias en el exterior por US$ 36 millones contra débitos en cuentas locales en moneda extranjera (“Canjes”), con efecto neutro en el resultado del mercado de cambios”.\n",
        "\"\"\"\n",
        "\n",
        "texto_tokenizado = nltk.word_tokenize(texto)\n",
        "\n",
        "def borrar_caracteres_no_ascii(palabras):\n",
        "    \"Borro caracteres no ascii\"\n",
        "    nuevas_palabras = []\n",
        "    for palabra in palabras:\n",
        "        nueva_palabra = unicodedata.normalize('NFKD', palabra).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        nuevas_palabras.append(nueva_palabra)\n",
        "    return nuevas_palabras\n",
        "\n",
        "\n",
        "def to_lowercase(palabras):\n",
        "    \"Convierto todas las palabras a lowercase\"\n",
        "    nuevas_palabras = []\n",
        "    for palabra in palabras:\n",
        "        nueva_palabra = palabra.lower()\n",
        "        nuevas_palabras.append(nueva_palabra)\n",
        "    return nuevas_palabras\n",
        "\n",
        "def remover_puntuacion(palabras):\n",
        "    \"Borro signos de puntuacion\"\n",
        "    nuevas_palabras = []\n",
        "    for palabra in palabras:\n",
        "        nueva_palabra = re.sub(r'[^\\w\\s]', '', palabra)\n",
        "        if nueva_palabra != '':\n",
        "            nuevas_palabras.append(nueva_palabra)\n",
        "    return nuevas_palabras\n",
        "\n",
        "def reemplazo_numeros(palabras):\n",
        "    \"Reemplazo los numeros por su denominacion en texto\"\n",
        "    p = inflect.engine()\n",
        "    nuevas_palabras = []\n",
        "    for palabra in palabras:\n",
        "        if palabra.isdigit():\n",
        "            nueva_palabra = p.number_to_words(palabra)\n",
        "            nuevas_palabras.append(nueva_palabra)\n",
        "        else:\n",
        "            nuevas_palabras.append(palabra)\n",
        "    return nuevas_palabras\n",
        "\n",
        "def borrar_stopwords(palabras):\n",
        "    \"\"\"StopWords son palabras que no aplican mucho significado al texto y pueden ser borradas como La El Etc\"\"\"\n",
        "    nuevas_palabras = []\n",
        "    for palabra in palabras:\n",
        "        if palabra not in stopwords.words('spanish'):\n",
        "            nuevas_palabras.append(palabra)\n",
        "    return nuevas_palabras\n",
        "\n",
        "\n",
        "def normalizar(palabras):\n",
        "    palabras = borrar_caracteres_no_ascii(palabras)\n",
        "    palabras = to_lowercase(palabras)\n",
        "    palabras = remover_puntuacion(palabras)\n",
        "    palabras = reemplazo_numeros(palabras)\n",
        "    palabras = borrar_stopwords(palabras)\n",
        "    return palabras\n",
        "\n",
        "palabras_normalizadas = normalizar(texto_tokenizado)\n",
        "\n",
        "print(palabras_normalizadas)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['socios', 'almacenamos', 'accedemos', 'informacion', 'dispositivo', 'tales', 'cookies', 'procesamos', 'datos', 'personales', 'tales', 'identificadores', 'unicos', 'informacion', 'estandar', 'enviada', 'dispositivo', 'anuncios', 'contenido', 'personalizados', 'medicion', 'anuncios', 'contenido', 'informacion', 'publico', 'asi', 'desarrollar', 'mejorar', 'productos', 'permiso', 'socios', 'podemos', 'utilizar', 'datos', 'localizacion', 'geografica', 'precisa', 'identificacion', 'mediante', 'caracteristicas', 'dispositivos', 'puede', 'hacer', 'clic', 'otorgarnos', 'consentimiento', 'socios', 'llevemos', 'cabo', 'procesamiento', 'previamente', 'descrito', 'forma', 'alternativa', 'puede', 'acceder', 'informacion', 'mas', 'detallada', 'cambiar', 'preferencias', 'otorgar', 'negar', 'consentimiento', 'cuenta', 'algun', 'procesamiento', 'datos', 'personales', 'puede', 'requerir', 'consentimiento', 'usted', 'derecho', 'rechazar', 'tal', 'procesamiento', 'preferencias', 'aplicaran', 'solo', 'sitio', 'web', 'puede', 'cambiar', 'preferencias', 'cualquier', 'momento', 'entrando', 'nuevo', 'sitio', 'web', 'visitando', 'politica', 'privacidad', 'banco', 'central', 'senalaron', 'hoy', 'tasa', 'interes', 'operaciones', 'ronda', 'promedio', 'forty-three', 'anual', 'caso', 'pasajes', 'paquetes', 'turismo', 'interno', 'mismos', 'podran', 'comercializar', 'traves', 'programa', 'ahora', 'twelve', 'textualmente', 'comunicacion', 'seven thousand, four hundred and seven', 'difundida', 'jueves', 'dice', 'partir', 'two hundred and sixty-one thousand, one hundred and twenty-one', 'entidades', 'financieras', 'financieras', 'emisoras', 'tarjetas', 'credito', 'deberan', 'financiar', 'cuotas', 'compras', 'efectuadas', 'mediante', 'tarjetas', 'credito', 'clientes', 'personas', 'humanas', 'juridicas', 'pasajes', 'exterior', 'demas', 'servicios', 'turisticos', 'exterior', 'tales', 'alojamiento', 'alquiler', 'auto', 'etc', 'realizadas', 'forma', 'directa', 'prestador', 'servicio', 'indirecta', 'traves', 'agencia', 'viajes', 'turismo', 'plataformas', 'web', 'u', 'intermediarios', 'nueva', 'restriccion', 'anuncio', 'banco', 'central', 'refuerza', 'politica', 'cuidar', 'lugar', 'cada', 'vez', 'mas', 'escasas', 'reservas', 'netas', 'administra', 'organismo', 'preside', 'miguel', 'pesce', 'temor', 'autoridades', 'apertura', 'fronteras', 'menores', 'restricciones', 'ingresar', 'paises', 'llegada', 'temporada', 'vacaciones', 'demanda', 'dolares', 'turismo', 'incrementara', 'sensiblemente', 'aumentando', 'presion', 'reservas', 'segun', 'ultimo', 'informe', 'mercado', 'cambiario', 'elaborado', 'banco', 'central', 'denominadas', 'personas', 'humanas', 'compraron', 'forma', 'neta', 'us', 'three hundred and twenty-six', 'millones', 'basicamente', 'gastos', 'efectuados', 'tarjetas', 'consumos', 'proveedores', 'residentes', 'neto', 'us', 'one hundred and forty-nine', 'millones', 'mostrando', 'incremento', 'fourteen', 'respecto', 'mes', 'anterior', 'atesoramiento', 'neto', 'us', 'one hundred and thirty-four', 'millones', 'billetes', 'incremento', 'eight', 'respecto', 'mes', 'previo', 'descenso', 'seventy-nine', 'interanual', 'asimismo', 'realizaron', 'transferencias', 'fondos', 'hacia', 'cuentas', 'propias', 'exterior', 'us', 'thirty-six', 'millones', 'debitos', 'cuentas', 'locales', 'moneda', 'extranjera', 'canjes', 'efecto', 'neutro', 'resultado', 'mercado', 'cambios']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egYbTVswTOod"
      },
      "source": [
        "#Conclusiones\n",
        "\n",
        "Con el ejercicio planteado y resuelto, podemos ver lo poderoso que es el lenguaje python y sus infinitas bibliotecas.\n",
        "\n",
        "El hecho de poder importar funcionalidad complejas y ejecutarlas facilmente, nos permite abstraernos de la complejidad del algoritmo y enfocarnos en el problema general.\n",
        "\n",
        "Una vez hecha la normalizacion del texto, existen muchas mas bibliotecas python para seguir procesando y darle valor y sentido a la normalizacion del texto.\n",
        "\n",
        "Algunas de estas bibliotecas son: TextBlob, Standford CoreNLP, Spacy, Textacy, Gensim, pyLDAvis etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGYucG9tU0IW"
      },
      "source": [
        "#Bibliografía\n",
        "\n",
        "[Que es el Procesamiento Natural? - IDB blog](https://blogs.iadb.org/conocimiento-abierto/es/que-es-el-procesamiento-de-lenguaje-natural-y-como-ponerlo-en-practica-con-recursos-abiertos/)\n",
        "\n",
        "[Ntlk docs](https://www.nltk.org/)\n",
        "\n",
        "[Procesamiento lenguaje natural - Universidad Catalunya](http://datascience.recursos.uoc.edu/es/procesamiento-del-lenguaje-natural-nlp/)"
      ]
    }
  ]
}